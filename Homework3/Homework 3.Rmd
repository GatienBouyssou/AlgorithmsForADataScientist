---
subtitle: "Pattern Mining and Social Network Analysis"
title: "Homework 3"
author: "BOUYSSOU Gatien , de POURTALES Caroline, LAMBA Ankit"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 6
---
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=6, fig.height=5)
library(reticulate)
#use_python("/Library/Frameworks/Python.framework/Versions/3.6/bin/python3", required = T)
knitr::knit_engines$set(python.reticulate =  TRUE)
#py_install("matplotlib")
#py_install("scikit-learn")
```

```{r rpackages,eval=TRUE,echo=FALSE}
#install.packages("fpc")
#install.packages("arules")
#install.packages("arulesCBA")
library(magrittr)
library(knitr)
library(arulesCBA)
library(rmarkdown)
library(arules)
library(arulesViz)
library(cluster)
library(caret)
```


\clearpage

# Parameters in association rules

There are parameters controlling the number of rules to be generated.

For A => B :

## Support

Support is an indication of how frequently the itemset appears in the dataset.

$$Support = \frac{\text{Number of transaction with both A and B}}{\text{Total Number of transaction}} = P(A \cap B)$$

## Confidence

Confidence is an indication of how often the rule has been found to be true.

$$Confidence = \frac{\text{Number of transaction with both A and B}}{\text{Total Number of transaction with A}} = \frac{P(A \cap B)}{P(A)}$$

## Lift

Lift is the factor by which, the co-occurence of A and B exceeds the expected probability of A and B co-occuring, had they been independent. So, higher the lift, higher the chance of A and B occurring together.

$$Lift = \frac{P(A \cap B)}{P(A) *P(B)}$$

## Leverage

$levarage(A→B)=support(A→B)−support(A)×support(B)$

The leverage compares the frequency of A and B appearing together and the frequency that would be expected if A and B were independent. Therefore, if

$support(A→C)=support(A)×support(C) $

then A and C are independent.

## Conviction

$conviction(A → B)=\frac{1−support(B)}{1−confidence(A→B)}$

or

$conviction(A → C)=\frac{1 - P(B)}{1- \frac{P(A \cap B)}{P(A)}}$

The conviction correspond to the frequency of items that are not B in the transaction over the frequency of B that don't contain A among all the transcations with B. Therefore, if A and B are independent the conviction should be equal to 1. When the confidence tends toward 1 the conviction tends toward infinity. It would mean that A and B are higly dependant.

\clearpage

# Apriori algorithm

## Definition

Apriori searches for frequent itemset browsing the lattice of itemsets in breadth. \newline
The database is scanned at each level of lattice. Additionally, Apriori uses a pruning technique based on the properties of the itemsets, which are: If an itemset is frequent, all its sub-sets are frequent and not need to be considered.

## Example on Groceries data

```{r}
data("Groceries")
#class(Groceries)
inspect(head(Groceries))
```

### On R

```{r, eval=TRUE, echo=FALSE}
grocery_rules <- apriori(Groceries, parameter = list(support = 0.03, confidence = 0.2))
```

```{r, eval=TRUE, echo=FALSE}
grocery_rules
inspect(head(sort(grocery_rules, by = "confidence", decreasing=TRUE), 5))
```

```{r}
#A DEVELOPPER
d <- dissimilarity(grocery_rules,method = "Jaccard")
pam <- pam(d, k = 5)
pam$clustering

clusters_hiearchical <- hclust(d, method = "complete")
clusterCut <- cutree(clusters_hiearchical, 3)
clusterCut
plot(clusters_hiearchical)
```


\clearpage

# Using Frequent itemset to find rules

## Concept


TO DO


## Example on personal data

We call also use the ruleInduction method to find closed frequent itemset.

ruleInduction has as attribute a method function.


Closed Frequent itemsets :

An itemset X is a closed frequent itemset in set S if X is both closed and frequent in S.


Eclat algorithm :

Mine frequent itemsets \newline
This algorithm uses simple intersection operations for equivalence class clustering along with bottom-up lattice traversal.

### On R

```{r, eval=TRUE, echo=FALSE}
data("Adult")
#class(Adult)
inspect(head(Adult,5))
```

```{r, eval=TRUE, echo=FALSE}
frequentItemsAdult <- eclat (Adult, parameter = list(supp = 0.01, maxlen = 100))
```

```{r, eval=TRUE, echo=FALSE}
#inspect(head(frequentItemsAdult,5))
itemFrequencyPlot(Adult, topN=15, type="absolute", main="Item Frequency")
```

If in control method = "apriori" is used, a very simple rule induction method is used. All rules are mined from the transactions data set using Apriori with the minimal support found in itemsets. And in a second step all rules which do not stem from one of the itemsets are removed. This procedure will be in many cases very slow (e.g., for itemsets with many elements or very low support).

```{r}
## Create rules from the itemsets
rulesAdult <- ruleInduction(frequentItemsAdult, confidence = 0.95, control = list(method = "apriori"))
inspect(head(sort(rulesAdult, by = "lift", decreasing=TRUE), 5))
```

If in control method = "ptree" is used, the transactions are counted into a prefix tree and then the rules are selectively generated using the counts in the tree. This is usually faster than the above approach.

```{r}
## Create rules from the itemsets
rulesAdult <- ruleInduction(frequentItemsAdult, Adult, confidence = 0.95, control = list(method = "ptree"))
inspect(head(sort(rulesAdult, by = "lift", decreasing=TRUE), 5))
```


NOW THE BIG QUESTION ???

How to win money ?

```{r}
frequentItemsAdultGain <- eclat (Adult, parameter = list(supp = 0.01, maxlen = 200))
rulesAdult <- ruleInduction(frequentItemsAdultGain, confidence = 0.15, control = list(method = "apriori"))
rulesAdult <- subset(rulesAdult, rhs %pin% "capital-gain=High")
```
```{r}
rulesAdult
inspect(head(sort(rulesAdult, by = "lift", decreasing=TRUE), 14))
```

### With python and scikit-learn


This database contains a lot of mushrooms with a set of characteristics. Each mushroom is classified either as edible or poisonous. The database has been found in kaggle and is available here : https://www.kaggle.com/uciml/mushroom-classification.

```python
import pandas as pd
import urllib
import matplotlib.pyplot as plt
import numpy as np
import os
from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth
from mlxtend.preprocessing import TransactionEncoder
```


```python
mush_data = pd.read_csv('./dataPython/mushrooms.csv')
```

First, we want to have an overview of the data.

```python
mush_data.head()
```
As we can see, each column contains values that are single characters. Their meaning is given by the file values_name.txt.

```python
len(mush_data)
```

Now, we want to know the data repartition for each columns.

```python
for column in mush_data.columns:
    print("\n" + column)
    print(mush_data[column].value_counts())
```

As you can see the there is almost as much poisonous as edible mushrooms. Moreover, the dataset contains some unknown values in the column stalk-root. We are going to discard those rows to keep lines that are complete.

```python
mush_data = mush_data[mush_data["stalk-root"] != '?']
```


```python
len(mush_data)
```

```python
mush_data['class'].value_counts()
```

Even without the discarded lines the dataset still have plenty of data and the class label is almost balanced. Before feeding the apriori algorithm with our data, we need to use the TransactionEncoder provided by mlxtend. This class transforms our data into a matrix where :

- each possible value for each feature will become a column
- for each mushroom and each column we assign a boolean that correspond to weither or not the feature is contained by the mushroom.

For example, such a dataset :

\begin{table}[]
\begin{tabular}{ll}
Columns : & odor    \\
0         & pungent \\
1         & almond  \\
2         & anise   \\
3         & pungent \\
4         & none
\end{tabular}
\end{table}

Will be changed into this matrix :

\begin{table}[]
\begin{tabular}{lllll}
Columns : & pungent & almond & anise & none  \\
0         & True    & False  & False & False \\
1         & False   & True   & False & False \\
2         & False   & False  & True  & False \\
3         & True    & False  & False & False \\
4         & False   & False  & False & True
\end{tabular}
\end{table}

The mushroom dataset contains characters values. In order to have columns that are bit more intelligible we will replace the character values by their full name.

This function above split for one feature the one character values from the full name values. It returns two arrays with each type of values.

```python
def sepCurrentValFromNewVal(stringNewOldValues):
    currentVal = []
    newVal = []
    arrayNOvalues = stringNewOldValues.split(",")
    for NOValues in arrayNOvalues:
        NO = NOValues.split('=')
        currentVal.append(NO[1])
        newVal.append(NO[0])
    return [currentVal, newVal]
```

This function goes through all the features and maps the feature's names with the character and full name values. Therefore it changes this line :

cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s

into that dictionary :

{'cap-shape' : [['b', 'c', 'x', 'f', 'k', 's'],
 ['bell', 'conical', 'convex', 'flat', 'knobbed', 'sunken']]}

Then, we will replace the values in the first array by the values of the second one for a given column.

```python
mapColumnValName = {}
with open("./dataPython/values_name.txt", "r") as file:
    line = file.readline()
    while line != "":
        line = line.replace(' ', "").replace("\n", "")
        valuesNamesForColumn = line.split(':')
        mapColumnValName[valuesNamesForColumn[0]] = sepCurrentValFromNewVal(valuesNamesForColumn[1])
        line = file.readline()
mapColumnValName['cap-shape']
```


```python
for column, ONValues in mapColumnValName.items():
    mush_data[column] = mush_data[column].replace(ONValues[0], ONValues[1])
mush_data.head()
```

```python
train_data = mush_data.values
```

```python
te = TransactionEncoder()
te_ary = te.fit(train_data).transform(train_data)
df = pd.DataFrame(te_ary, columns=te.columns_)
len(df.head())
```

```python
frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)
frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))
frequent_itemsets
```

Thanks to the apriori algorithm it is possible to associate some feature together.

```python
frequent_itemsets[frequent_itemsets['itemsets'].astype(str).str.contains("edible")]
```

```python
frequent_itemsets[frequent_itemsets['itemsets'].astype(str).str.contains("poisonous")]
```

With the apriori algorithm, we can see some associations with the \textit{edible} feature with a support around 0.6. Also, it seems that the apriori haven't found any associations with the \textit{poisonous} feature with a support above 0.6.

The result given by apriori will be used by the association_rules function given by mixtend.

```python
assos_rule = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.9)
```

```python
assos_rule[assos_rule['antecedents'].astype(str).str.contains("edible")]
```
Here we are listing all the rules that are implied by edible. Of course, we need to know the rules where edible is implied (ie the rules where edible is contained by the consequents column). But before searching for those rules, we are going to try out another algorithm, named fpgrowth, to see if we can obtain different results.

```python
frequent_itemsets = fpgrowth(df, min_support=0.6, use_colnames=True)
```

```python
frequent_itemsets[frequent_itemsets['itemsets'].astype(str).str.contains("edible")]
```

The results above obtained by fpgrowth look similar to the results obtained by the apriori algorithm. Therefore, now we can look for the rules that implies edible.


```python
assos_rule = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)
```

```python
assos_rule[assos_rule['consequents'].astype(str).str.contains("edible")]
```

```python
assos_rule = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.6)
```


```python
assos_rule[assos_rule['consequents'].astype(str).str.contains("edible")]
```

As we can see above if the threshold is above 0.6 the association_rules function does not find any rules where edible is implied. The confidence and the consequent support of the rules lies around 60%. Therefore, they cannot be considered as reliable.

\clearpage

# Clustering with Apriori algorithm as dissimilarity measure

## Concept

TO DO

### Example on tennis data

```{r}
id <- "1GNbIhjdhuwPOBr0Qz82JMkdjUVBuSoZd"
tennisData <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",id), header = T)
```

#### On R

```{r, eval=TRUE, echo=FALSE, fig.height = 5, fig.width = 10, fig.align = "center"}
tennisTransactions <- tennisData[,3:7]
tennisTransactions <- data.frame(tennisTransactions)

tennisTransactions[["ACE.1"]] <- ordered(cut(tennisTransactions[[ "ACE.1"]],
  c(-Inf,0, median(tennisTransactions[[ "ACE.1"]][tennisTransactions[[ "ACE.1"]]>0]),
  Inf)), labels = c("None", "Low", "High"))

tennisTransactions[["ACE.2"]] <- ordered(cut(tennisTransactions[[ "ACE.2"]],
  c(-Inf,0, median(tennisTransactions[[ "ACE.2"]][tennisTransactions[[ "ACE.2"]]>0]),
  Inf)), labels = c("None", "Low", "High"))

tennisTransactions[["UFE.2"]] <- ordered(cut(tennisTransactions[[ "UFE.2"]],
  c(-Inf,0, median(tennisTransactions[[ "UFE.2"]][tennisTransactions[[ "UFE.2"]]>0]),
  Inf)), labels = c("Low", "High"))

tennisTransactions[["UFE.1"]] <- ordered(cut(tennisTransactions[[ "UFE.1"]],
  c(-Inf,0, median(tennisTransactions[[ "UFE.1"]][tennisTransactions[[ "UFE.1"]]>0]),
  Inf)), labels = c("Low", "High"))

tennis[["Result"]] <- as.factor(tennis[["Result"]])

tennis <- as(tennis, "transactions")

inspect(head(tennisTransactions1,5))
```

The associations rules for Player-1 winning :

```{r, eval=TRUE, echo=FALSE}
tennis_rules_winning <- apriori(tennisTransactions1, appearance = list (default="lhs",rhs="Result=1"), parameter = list(support = 0.15, confidence = 0.3))
```

```{r, eval=TRUE, echo=FALSE}
tennis_rules_winning
inspect(head(sort(tennis_rules_winning, by = "lift", decreasing=TRUE), 5))
```

The associations rules for Player-1 loosing :

```{r, eval=TRUE, echo=FALSE}
tennis_rules_loosing <- apriori(tennisTransactions1, appearance = list (default="lhs",rhs="Result=0"), parameter = list(support = 0.15, confidence = 0.3))
```

```{r, eval=TRUE, echo=FALSE}
tennis_rules_loosing
inspect(head(sort(tennis_rules_loosing, by = "lift", decreasing=TRUE), 5))
```

All the rules with Result as association :

```{r, eval=TRUE, echo=FALSE}
tennis_rules <- apriori(tennisTransactions1, appearance = list (default="lhs",rhs=list("Result=0","Result=1")), parameter = list(support = 0.2, confidence = 0.4))
```

```{r, eval=TRUE, echo=FALSE}
tennis_rules
inspect(head(sort(tennis_rules, by = "lift", decreasing=TRUE), 5))
```


Cluster the results :

```{r}
inspect(tennis_rules)

d <- dissimilarity(tennis_rules,method = "Jaccard")
clusters_hiearchical <- hclust(d, method = "complete")
clusterCut <- cutree(clusters_hiearchical, 2)
clusterCut
plot(clusters_hiearchical)
```

This clustering regroups Player-1 winner together very well.


## The CLIQUE algorithm

## The ENCLUS algorithm

ENtropy-based CLUStering

\clearpage

# Frequent pattern-based classification

## Classification based on Association

### CBA Algorithm

Implementation the CBA algorithm with the M1 or M2 pruning strategy introduced by Liu, et al. (1998).

Candidate classification association rules (CARs) are mined with the standard APRIORI algorithm. Rules are ranked by confidence, support and size. Then either the M1 or M2 algorithm are used to perform database coverage pruning and to determin the number of rules to use and the default class.

TO DO DEFINITION

### Example on tennis data

#### Recall from Homework 1

With Random Forest, the accuracy rate was 0.6931818.\newline
With Logistic regression it was 0.7667.

#### From classification to associations rules

```{r}
tennisClassifier <- tennisData

tennisClassifier[["ACE.1"]] <- as.numeric(tennisClassifier[["ACE.1"]])

tennisClassifier[["ACE.2"]] <- as.numeric(tennisClassifier[["ACE.2"]])

tennisClassifier[["UFE.2"]] <- as.numeric(tennisClassifier[["UFE.2"]])

tennisClassifier[["UFE.1"]] <- as.numeric(tennisClassifier[["UFE.1"]])

tennisClassifier[["Result"]] <- as.factor(tennisClassifier[["Result"]])

# test and train set
n = dim(tennisClassifier)[1]
n2 = n*(3/4)
set.seed(1234)
train = sample(c(1:n), replace = F)[1:n2]
tennisTest = tennisClassifier[-train, ]
tennisTrain = tennisClassifier[train, ]

#Learn a classifier using automatic default discretization
classifier <- CBA(Result ~ ACE.1 + ACE.2 + UFE.1 + UFE.2, data = tennisTrain, disc.method = "chi2", supp = 0.1, conf=0.6)

# inspect the rule base
inspect(rules(classifier))
```

```{r}
# make predictions
classifier.prediction = predict(classifier, tennisTest)
classifier.confusion_matrix = table(classifier.prediction, true = tennisTest$Result)
classifier.confusion_matrix
```


The accuracy rate is :
```{r, eval=TRUE, echo=FALSE}
model.accuracyrate = (classifier.confusion_matrix[1,1] + classifier.confusion_matrix[2,2]) / (classifier.confusion_matrix[1,1] + classifier.confusion_matrix[1,2] + classifier.confusion_matrix[2,1] +classifier.confusion_matrix[2,2])
model.accuracyrate
```

The sensitivity is the percentage of true output giving Player1-winner among the population of true Player1-winner :
```{r, eval=TRUE, echo=FALSE}
model.sensitivity = classifier.confusion_matrix[2,2]/(classifier.confusion_matrix[1,2] + classifier.confusion_matrix[2,2])
model.sensitivity
```

The specificity is the percentage of true output giving Player2-winner (= Player1-looser) among the population of true Player2-winner:
```{r, eval=TRUE, echo=FALSE}
model.specificity = classifier.confusion_matrix[1,1]/(classifier.confusion_matrix[1,1] + classifier.confusion_matrix[2,1])
model.specificity
```

The precision is the percentage of true output giving Player1-winner among all the outputs giving Player1-winner (even if not winner) :
```{r, eval=TRUE, echo=FALSE}
model.precision = classifier.confusion_matrix[2,2]/(classifier.confusion_matrix[2,1] + classifier.confusion_matrix[2,2])
model.precision
```

So the F_Mesure is :
```{r, eval=TRUE, echo=FALSE}
model.fmesure = (2*model.precision*model.sensitivity)/(model.sensitivity + model.precision)
model.fmesure
```


#### From associations rules to classification

```{r}
#Learn classifier from transactions
tennisTransactions2 <- prepareTransactions(Result ~ ., tennisTransactions, disc.method = "mdlp")
inspect(head(tennisTransactions2,4))
tennisTransactionsTrain <- tennisTransactions2[train,]
tennisTransactionsTest <- tennisTransactions2[-train,]

classifier <- CBA(Result ~ ACE.1 + ACE.2 + UFE.1 + UFE.2, data = tennisTransactionsTrain, supp = 0.1, conf = 0.6, verbose = TRUE)
```

```{r}
# make predictions
classifier.prediction = predict(classifier, tennisTransactionsTest)
classifier.confusion_matrix = table(classifier.prediction, response(Result ~ ACE.1 + ACE.2 + UFE.1 + UFE.2, tennisTransactionsTest))

classifier.confusion_matrix
```
The accuracy rate is :
```{r, eval=TRUE, echo=FALSE}
model.accuracyrate = (classifier.confusion_matrix[1,1] + classifier.confusion_matrix[2,2]) / (classifier.confusion_matrix[1,1] + classifier.confusion_matrix[1,2] + classifier.confusion_matrix[2,1] +classifier.confusion_matrix[2,2])
model.accuracyrate
```

The sensitivity is the percentage of true output giving Player1-winner among the population of true Player1-winner :
```{r, eval=TRUE, echo=FALSE}
model.sensitivity = classifier.confusion_matrix[2,2]/(classifier.confusion_matrix[1,2] + classifier.confusion_matrix[2,2])
model.sensitivity
```

The specificity is the percentage of true output giving Player2-winner (= Player1-looser) among the population of true Player2-winner:
```{r, eval=TRUE, echo=FALSE}
model.specificity = classifier.confusion_matrix[1,1]/(classifier.confusion_matrix[1,1] + classifier.confusion_matrix[2,1])
model.specificity
```

The precision is the percentage of true output giving Player1-winner among all the outputs giving Player1-winner (even if not winner) :
```{r, eval=TRUE, echo=FALSE}
model.precision = classifier.confusion_matrix[2,2]/(classifier.confusion_matrix[2,1] + classifier.confusion_matrix[2,2])
model.precision
```

So the F_Mesure is :
```{r, eval=TRUE, echo=FALSE}
model.fmesure = (2*model.precision*model.sensitivity)/(model.sensitivity + model.precision)
model.fmesure
```


## Classification based on Multiple Association Rules

## Classification based on Predictive Association Rules


\clearpage

# Evaluation

Compare the algorithms
